{
  "versions": [
    {
      "version": "1.10.1",
      "changes": [
        "Fixed critical initialization order bug in InferenceService to prevent potential crashes",
        "Enhanced security: Restricted token revocation to internal app only",
        "Optimized TokenManager validation performance with O(1) lookup",
        "Fixed UI bug with duplicate button state updates",
        "Added support for .bin and .tflite model file extensions in model selector",
        "Improved concurrency safety in ConversationManager and AiEngineManager"
      ]
    },
    {
      "version": "1.10.0",
      "changes": [
        "Implemented local persistence for all active conversations",
        "Conversations are now automatically reloaded from disk after service restarts or crashes",
        "TTL (Time-To-Live) is strictly validated during recovery to ensure stale data is discarded",
        "Synchronization: Every message addition or setting change is mirrored to secure internal storage"
      ]
    },
    {
      "version": "1.9.4",
      "changes": [
        "Enabled real-time response logging in the UI console",
        "Added 'Generating response...' status indicator when inference begins",
        "Full AI responses are now logged directly to the UI console for complete diagnostic visibility"
      ]
    },
    {
      "version": "1.9.3",
      "changes": [
        "Enhanced 'health' and 'getLoad' to verify model state: Returns error if engine is not initialized",
        "Improved diagnostic reliability by preventing false 'ok' status during model loading or failure"
      ]
    },
    {
      "version": "1.9.2",
      "changes": [
        "Enforced mandatory API token authentication for 'ping', 'health', and 'getLoad' endpoints",
        "Achieved 'Zero-Communication' policy: No server interaction possible without a valid token",
        "Updated AIDL interface to include apiToken parameter for all diagnostic queries"
      ]
    },
    {
      "version": "1.9.1",
      "changes": [
        "Expanded 'Verification & Tests' UI with dedicated Health Check and Get Load buttons",
        "Improved server diagnostic visibility for internal testing and verification",
        "Fixed method binding for getLoad() in Kotlin MainActivity"
      ]
    },
    {
      "version": "1.9.0",
      "changes": [
        "Added 'health' endpoint to AIDL interface for instantaneous server status checks",
        "Added 'getLoad' endpoint to track active and pending inference requests",
        "Implemented Atomic request tracking for accurate real-time load reporting",
        "Ensured diagnostic requests are non-blocking and served even during heavy inference"
      ]
    },
    {
      "version": "1.8.0",
      "changes": [
        "Implemented Custom TTL (Time-To-Live) for conversations",
        "Updated AIDL interface: startConversation() now accepts a custom ttlMs parameter",
        "Maintained default 30-minute expiration for backward compatibility"
      ]
    },
    {
      "version": "1.7.0",
      "changes": [
        "Implemented Smart Session Reuse: Reuses active engine session for consecutive messages in the same conversation",
        "Enabled KV Cache persistence for multi-turn chats, significantly improving response speed",
        "Optimized resource usage by avoiding full context reconstruction when not switching users"
      ]
    },
    {
      "version": "1.6.0",
      "changes": [
        "Removed Assistant Message Continuation support (prefilling) due to engine limitations",
        "Implemented 'Single-Conversation-Per-Turn' strategy for consistent state",
        "Restored detailed debug logging for incoming messages and tokens"
      ]
    },
    {
      "version": "1.5.2",
      "changes": [
        "Updated AIDL interface: startConversation() now accepts an optional systemInstruction parameter",
        "System Prompts are now set explicitly at conversation start, rather than inferred from the first message",
        "Removed message filtering logic: All messages sent during inference are processed (system messages fallback to user role)",
        "Updated documentation to reflect new conversation initialization workflow"
      ]
    },
    {
      "version": "1.5.1",
      "changes": [
        "Restored System Preamble logic: First system message is used as session instruction",
        "Subsequent system messages are gracefully handled as user messages to preserve context",
        "Updated AiEngineManager to use synchronous sendMessage for history updates (workaround for missing addMessage)",
        "Fixed critical issue where system instructions were treated as duplicate user messages",
        "Ensured ConversationConfig systemInstruction is never null"
      ]
    },
    {
      "version": "1.5.0",
      "changes": [
        "Major architecture overhaul: Transitioned to a stateful conversation-based model",
        "Implemented unique Conversation IDs with persistent engine state",
        "Support for 32k context window (32,768 tokens)",
        "Raw message appending: All messages in a request are added to the engine state",
        "Sync/Async hybrid flow for reliable multi-message processing",
        "Added TTL (Time-To-Live) management with automatic resource cleanup",
        "Refactored AIDL interface for stateful conversation lifecycle"
      ]
    },
    {
      "version": "1.4.1",
      "changes": [
        "Implemented fully manual Prefill+Decode streaming for maximum control",
        "Assistant message continuation now works correctly with true token-by-token streaming",
        "Replaced high-level generateContentStream with direct runPrefill/runDecode calls",
        "Added comprehensive debug logging for inference pipeline visibility"
      ]
    },
    {
      "version": "1.4.0",
      "changes": [
        "Added 'Test Multi-Turn' and 'Test Contin.' buttons to the main UI",
        "Fixed critical bug where Assistant Message Continuation (prefilling) was ignored",
        "Implemented advanced control flow (Prefill + Decode) for correct partial message completion",
        "Restored standard GenerateContentStream logic for normal user turns to prevent empty input errors"
      ]
    },
    {
      "version": "1.3.15",
      "changes": [
        "Added explicit AIDL intent-filter for better external app discoverability",
        "Improved service visibility for Android 11+ client applications",
        "Streamlined binding process for third-party integrations"
      ]
    },
    {
      "version": "1.3.14",
      "changes": [
        "Implemented transparent IPC request logging in the main UI",
        "Identifies and logs external application package names making AIDL calls",
        "Logs all requests (StartSession, Inference, Ping) regardless of auth status",
        "Ensures invalid tokens are visible in the logs for easier developer debugging"
      ]
    },
    {
      "version": "1.3.13",
      "changes": [
        "Enhanced InferenceService with robust JSON response handling",
        "Added 'ping()' method to AIDL for basic health and connectivity checks",
        "Implemented automatic token trimming to prevent auth failures from whitespace",
        "Added comprehensive try-catch wrappers around binder methods to prevent silent failures",
        "Improved diagnostic logging for token validation and session lifecycle"
      ]
    },
    {
      "version": "1.3.12",
      "changes": [
        "Fixed critical gap in 'approveRequest' persistence",
        "Tokens approved via UI are now correctly written to the backup file",
        "Ensures new approvals survive crashes even if SharedPreferences fails"
      ]
    },
    {
      "version": "1.3.11",
      "changes": [
        "Implemented security restriction to block client-side token revocation",
        "Only the Edge AI Core app (owner) can now revoke tokens",
        "External authorization calls to 'revokeApiToken' are silently rejected"
      ]
    },
    {
      "version": "1.3.10",
      "changes": [
        "Implemented 'Double Persistence' strategy for API tokens",
        "Added fail-safe backup file (filesDir/auth_tokens_backup.json)",
        "System now attempts self-repair from backup if SharedPreferences are corrupted or empty",
        "Guaranteed persistence for authorized apps against process kills and disk flakiness"
      ]
    },
    {
      "version": "1.3.9",
      "changes": [
        "Fixed major bug where tokens were lost due to unnecessary disk reloading",
        "Optimized Singleton TokenManager to trust in-memory state as the source of truth",
        "Removed redundant data loading logic to prevent stale disk reads from overwriting memory",
        "Streamlined persistence logic for maximum stability under high concurrency"
      ]
    },
    {
      "version": "1.3.8",
      "changes": [
        "Resolved deep-seated concurrency bug in TokenManager using Singleton pattern",
        "Implemented global synchronization locks for all token operations",
        "Fixed race condition between 'loadData' and 'persist' that caused token loss",
        "Standardized on unified in-memory state for Service and UI processes",
        "Added parse-failure protection to prevent overwriting tokens with empty data"
      ]
    },
    {
      "version": "1.3.7",
      "changes": [
        "Fixed critical multi-process race condition causing tokens to disappear",
        "Implemented atomic token persistence using synchronous commit and granular keys",
        "Enhanced TokenManager with mandatory cross-process data synchronization",
        "Separated persistence logic for approved tokens and pending requests"
      ]
    },
    {
      "version": "1.3.6",
      "changes": [
        "Polished UI to strictly adhere to Material Design 3 standards",
        "Refined spacing, typography, and card designs across all pages",
        "Added descriptive icons to all action buttons and test interfaces",
        "Enhanced README with detailed Multi-Session management documentation",
        "Improved Backend selection UI with better touch targets and visual grouping"
      ]
    },
    {
      "version": "1.3.5",
      "changes": [
        "Implemented true multi-session support for concurrent clients",
        "Added intelligent session tracking and automatic hardware resource fallback",
        "Systems on GPU now maintain multiple independent conversation contexts",
        "Graceful session switching on limited hardware (NPU/CPU)",
        "Fixed 'session already exists' errors during concurrent usage"
      ]
    },
    {
      "version": "1.3.4",
      "changes": [
        "Added 'Authorized Apps' list to manage and revoke API access",
        "Implemented token revocation with automatic session cleanup",
        "Fixed 'FAILED_PRECONDITION: A session already exists' error with engine retry logic",
        "Improved robustness of hardware resource management during rapid testing",
        "Enhanced Tokens UI with separate sections for Pending and Authorized apps"
      ]
    },
    {
      "version": "1.3.3",
      "changes": [
        "Test buttons now simulate full external app authentication flow",
        "Token request → Approval → Session → Inference → Close cycle",
        "Each test (Text, Vision, Audio) properly validates auth mechanism",
        "Sessions are properly closed after each test to free resources"
      ]
    },
    {
      "version": "1.3.2",
      "changes": [
        "Fixed critical NullPointerException during layout inflation",
        "Improved stability of NestedScrollView for log display"
      ]
    },
    {
      "version": "1.3.1",
      "changes": [
        "Fixed 'Service not bound' error by implementing auto-binding on status updates",
        "Improved log container scrolling behavior with NestedScrollView",
        "Made logs text selectable for easier debugging"
      ]
    },
    {
      "version": "1.3.0",
      "changes": [
        "Enforced mandatory stateful, session-based inference (stateless methods removed)",
        "Overhauled UI with Material Design 3 and Bottom Navigation",
        "Implemented Manual User Approval for API token generation",
        "Added package-based token mapping for enhanced security",
        "Consolidated settings into distinct Server, Backend, and Token screens",
        "Optimized inference performance via mandatory KV cache reuse"
      ]
    },
    {
      "version": "1.2.1",
      "changes": [
        "Implemented API token persistence across app restarts",
        "Added Backup and Restore features for API tokens",
        "Updated UI with dedicated token management actions"
      ]
    },
    {
      "version": "1.2.0",
      "changes": [
        "Added API token generation for client authentication",
        "Implemented session management with TTL (Time-To-Live) support",
        "Added session-based inference methods for KV cache reuse",
        "Sessions automatically clean up expired connections",
        "Updated AIDL interface with new token and session methods"
      ]
    },
    {
      "version": "1.1.2",
      "changes": [
        "Added support for System Prompts (preambles)",
        "Implemented sampling parameters: temperature, top_k, and max_tokens",
        "Updated documentation with detailed integration guide for new features"
      ]
    },
    {
      "version": "1.1.1",
      "changes": [
        "Fixed build error in AiEngineManager due to type mismatch",
        "Updated README with detailed streaming response integration guide",
        "Improved on-device inference text extraction"
      ]
    },
    {
      "version": "1.1.0",
      "changes": [
        "Implemented streaming output tokens for real-time inference feedback",
        "Added asynchronous AIDL interface for streaming responses",
        "Updated test inference UI to show tokens as they are generated"
      ]
    },
    {
      "version": "1.0.1",
      "changes": [
        "Fixed crash on Android 14+ due to missing foreground service permission",
        "Fixed 16KB page alignment crash by enabling native lib extraction",
        "Enabled cleartext traffic for local server access",
        "Implemented model path persistence",
        "Upgraded Gradle and build tools"
      ]
    },
    {
      "version": "1.0.0",
      "changes": [
        "Initial release",
        "Support for LiteRT-LM models (.litertlm)",
        "OpenAI-compatible API Server",
        "Test Inference feature"
      ]
    }
  ]
}